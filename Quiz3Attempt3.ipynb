{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "'''==================================================\n",
    "Initial set up\n",
    "=================================================='''\n",
    "def init():\n",
    "    #Hyperparameters\n",
    "    SMALL_ENOUGH = 0.005\n",
    "    GAMMA = 0.9         \n",
    "    NOISE = 0.1\n",
    "\n",
    "    #Define all states\n",
    "    all_states=[]\n",
    "    for i in range(4):\n",
    "        for j in range(6):\n",
    "                all_states.append((i,j))\n",
    "\n",
    "    #Define rewards for all states\n",
    "    rewards = {}\n",
    "    for i in all_states:\n",
    "        if i == (1,5):\n",
    "            rewards[i] = 1\n",
    "        elif i == (3,4):\n",
    "            rewards[i] = -1\n",
    "        elif i == (3,5):\n",
    "            rewards[i] = -1\n",
    "        else:\n",
    "            rewards[i] = 0\n",
    "\n",
    "    #Dictionnary of possible actions. We have three \"end\" states (1,5 and 3,4 and 3,5)\n",
    "    actions = {\n",
    "        (0,0):('D', 'R'), \n",
    "        (0,1):('D', 'R', 'L'),    \n",
    "        (0,2):('D', 'L', 'R'),\n",
    "        (0,3):('D', 'L', 'R'),\n",
    "        (0,4):('D', 'L', 'R'),\n",
    "        (0,5):('D', 'L'),\n",
    "        (1,0):('D', 'U', 'R'),\n",
    "        (1,1):('D', 'R', 'L', 'U'),\n",
    "        (1,2):('D', 'R', 'L', 'U'),\n",
    "        (1,3):('D', 'R', 'L', 'U'),\n",
    "        (1,4):('D', 'R', 'L', 'U'),\n",
    "        (2,0):('D', 'U', 'R'),\n",
    "        (2,1):('D', 'R', 'L', 'U'),\n",
    "        (2,2):('D', 'R', 'L', 'U'),\n",
    "        (2,3):('D', 'R', 'L', 'U'),\n",
    "        (2,4):('D', 'R', 'L', 'U'),\n",
    "        (2,5):('D', 'L', 'U'),\n",
    "        (3,0):('U', 'R'),\n",
    "        (3,1):('R', 'L', 'U'),\n",
    "        (3,2):('R', 'L', 'U'),\n",
    "        (3,3):('R', 'L', 'U'),\n",
    "        } #I'm not sure if this will work but its certainly a better organization of data\n",
    "\n",
    "    #Define an initial policy\n",
    "    policy={}\n",
    "    for s in actions.keys():\n",
    "        policy[s] = np.random.choice(actions[s])\n",
    "\n",
    "    #Define initial value function \n",
    "    V={}\n",
    "    for s in all_states:\n",
    "        if s in actions.keys():\n",
    "            V[s] = 0\n",
    "        if s ==(3,4):\n",
    "            V[s]= -1\n",
    "        if s == (3,5):\n",
    "            V[s]= -1\n",
    "        if s == (1,5):\n",
    "            V[s]= 1\n",
    "\n",
    "\n",
    "    start = [0]*24\n",
    "    row = [(0,0),(0,1),(0,2),(0,3),(0,4),(0,5),(1,0),(1,1),(1,2),(1,3),(1,4),(1,5),(2,0),(2,1),(2,2),(2,3),(2,4),(2,5),(3,0),(3,1),(3,2),(3,3),(3,4),(3,5)]\n",
    "    transition = { \n",
    "        tuple((0,0)):[], \n",
    "        tuple((0,1)):[],    \n",
    "        tuple((0,2)):[],\n",
    "        tuple((0,3)):[],\n",
    "        tuple((0,4)):[],\n",
    "        tuple((0,5)):[],\n",
    "        tuple((1,0)):[],\n",
    "        tuple((1,1)):[],\n",
    "        tuple((1,2)):[],\n",
    "        tuple((1,3)):[],\n",
    "        tuple((1,4)):[],\n",
    "        tuple((1,5)):[],\n",
    "        tuple((2,0)):[],\n",
    "        tuple((2,1)):[],\n",
    "        tuple((2,2)):[],\n",
    "        tuple((2,3)):[],\n",
    "        tuple((2,4)):[],\n",
    "        tuple((2,5)):[],\n",
    "        tuple((3,0)):[],\n",
    "        tuple((3,1)):[],\n",
    "        tuple((3,2)):[],\n",
    "        tuple((3,3)):[],\n",
    "        tuple((3,4)):[],\n",
    "        tuple((3,5)):[],\n",
    "        }\n",
    "    return rewards, actions, policy, V, transition\n",
    "#By the end of this, the grid, values, transitional model, and rewards have been set up\n",
    "#An initial policy has been established, which I guess will be a part of the actions taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_trial(actions,V):\n",
    "    Terminal = False\n",
    "    trial_list = []\n",
    "    start=random.choice([(0,0),(2,1)])\n",
    "    state = start\n",
    "    trial_list.append(state)\n",
    "\n",
    "    while not Terminal:\n",
    "        #choose an action randomly from the permissible actions\n",
    "        a = random.choice(actions[state])\n",
    "        ex = state[0]\n",
    "        why = state[1]\n",
    "        if a == 'U':\n",
    "            nxt = (ex-1, why)\n",
    "        if a == 'D':\n",
    "            nxt = (ex+1, why)\n",
    "        if a == 'L':\n",
    "            nxt = (ex, why-1)\n",
    "        if a == 'R':\n",
    "            nxt = (ex, why+1)\n",
    "        trial_list.append(nxt)\n",
    "\n",
    "        #now, a random state has been chosen and the next state established\n",
    "        value = V[nxt]\n",
    "\n",
    "        if value == 1:\n",
    "            Terminal = True\n",
    "            break\n",
    "        elif value == -1:\n",
    "            Terminal = True\n",
    "            break\n",
    "        state = nxt\n",
    "    return trial_list\n",
    "\n",
    "def find_indices(list_to_check, item_to_find):\n",
    "    indices = []\n",
    "    for idx, value in enumerate(list_to_check):\n",
    "        if value == item_to_find:\n",
    "            indices.append(idx)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def define_transition_model(row, transition_model, trials):\n",
    "    #Scanning (s,a,s')\n",
    "    for g in row:\n",
    "        s = g #The state we\n",
    "        for i in transition_model:\n",
    "            s_prime = i #Chossing column\n",
    "            N = 0 #Everytime the column shifts, everything should revert\n",
    "            N_all = 0\n",
    "            for h in trials:\n",
    "                num_inst = find_indices(h,g) #Number of times s was in a trial, for which the list of trials is iterated through\n",
    "                N_all += len(num_inst) #This then represents how many times we went from S to anywhere, including s' or otherwise\n",
    "                for m in num_inst:\n",
    "                    if m+1 < len(h):\n",
    "                        actual_s_prime = h[m+1] #What is the actual next item after every instance of S\n",
    "                    else:\n",
    "                        actual_s_prime = None\n",
    "                    if actual_s_prime == s_prime: #in the column we're \n",
    "                        N +=1 #Number of times in any trial that s came before s prime\n",
    "            #Now we have N and N_all, now we need to input N/ N_all into the proper space in the transition model\n",
    "            column = row.index(g)\n",
    "            if N_all != 0:\n",
    "                transition_model[tuple(i)].append(N/ N_all) #This should work bc we're iterating through g in order\n",
    "            else:\n",
    "                transition_model[tuple(i)].append(0)\n",
    "    return transition_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rewards, actions, policy, V, transition = init()\n",
    "\n",
    "class_example = True\n",
    "\n",
    "if class_example: #I'll have to set many other things to make this the case\n",
    "    #For testing against class example\n",
    "    trials = [0]*3\n",
    "    V[(2,1)] = -1\n",
    "    V[(2,2)] = 1\n",
    "    rewards[(2,1)] = -1\n",
    "    rewards[(2,2)] = 1\n",
    "\n",
    "    \n",
    "    trials[0] = [(0,0),(0,1),(0,2),(1,2),(2,2)]\n",
    "    trials[1] = [(0,0),(0,1),(1,1),(0,1),(0,2),(1,2),(2,2)]\n",
    "    trials[2] = [(0,0),(1,0),(0,0),(0,1),(0,2),(1,2),(2,2)]\n",
    "else:\n",
    "    trials = [0]*5\n",
    "    trials[0] = one_trial(actions,V)\n",
    "    trials[1]  = one_trial(actions,V)\n",
    "    trials[2]  = one_trial(actions,V)\n",
    "    trials[3]  = one_trial(actions,V)\n",
    "    trials[4]  = one_trial(actions,V)\n",
    "\n",
    "row = [(0,0),(0,1),(0,2),(0,3),(0,4),(0,5),(1,0),(1,1),(1,2),(1,3),(1,4),(1,5),(2,0),(2,1),(2,2),(2,3),(2,4),(2,5),(3,0),(3,1),(3,2),(3,3),(3,4),(3,5)]\n",
    "transition_update = define_transition_model(row,transition, trials)\n",
    "\n",
    "DF_transition = pd.DataFrame(transition_update, index=row)\n",
    "DF_transition.to_csv(\"transition.csv\")\n",
    "\n",
    "value_list = []\n",
    "reward_list = []\n",
    "states = []\n",
    "for j in V:\n",
    "    dataV = V[j]\n",
    "    dataR = rewards[j]\n",
    "    value_list.append(dataV)\n",
    "    reward_list.append(dataR)\n",
    "    states.append(j) #to keep track of which states we visited\n",
    "        \n",
    "trans_array = DF_transition.values\n",
    "\n",
    "row = len(value_list)\n",
    "value_array = np.array(value_list)\n",
    "val_arr = np.reshape(value_array,(row,1))\n",
    "reward_array = np.array(reward_list)\n",
    "rew_arr = np.reshape(reward_array,(row,1))\n",
    "\n",
    "\n",
    "\n",
    "#okay this is kinda jank but it works way better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V = R + Gamma*P*V\n",
    "# R = V - Gamma*P*V\n",
    "#Have to put it in the format of ax = b and the solution is x\n",
    "#R = [[1x24] - Gamma*P]V \n",
    "#Here, b =R, x = V, and a = [I[24x24] - Gamma*P*I[24x24]]\n",
    "B = rew_arr\n",
    "gamma = 0.9\n",
    "inv = np.identity(24)\n",
    "A = inv - (gamma*np.matmul(trans_array,inv))\n",
    "\n",
    "det = np.linalg.det(A)\n",
    "x = np.linalg.solve(A,B)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(x, index=states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to create a value equation for each state, then solve the system of equations once per trial\n",
    "gamma = 0.9\n",
    "for j in V:\n",
    "    #Now I relate all permissible options using actions\n",
    "    options = actions[j]\n",
    "    ex = j[0]\n",
    "    why = j[1]\n",
    "    nxtU = 0\n",
    "    nxtD = 0\n",
    "    nxtL = 0\n",
    "    nxtR = 0\n",
    "    #Maybe the approach is developing matrices instead...\n",
    "    for a in options:\n",
    "        if a == 'U':\n",
    "            nxtU = (ex-1, why)\n",
    "        if a == 'D':\n",
    "            nxtD = (ex+1, why)\n",
    "        if a == 'L':\n",
    "            nxtL = (ex, why-1)\n",
    "        if a == 'R':\n",
    "            nxtR = (ex, why+1)\n",
    "        #Now I have all the surrounding states\n",
    "    \n",
    "\n",
    "\n",
    "    V[j] = rewards[j] + gamma*(V[nxtU])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df5c7b8ffaedf80dec2b70b09605990d7e0e1b6bc745b497330e86cbe58a738e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
