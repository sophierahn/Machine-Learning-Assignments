{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82d2YX9-Fonj"
      },
      "source": [
        "0.0 Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_HAoyxe8nCJD"
      },
      "outputs": [],
      "source": [
        "#Importing packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "import math as m\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random as rand\n",
        "import csv\n",
        "from google.colab import drive\n",
        "from mpl_toolkits import mplot3d\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import random\n",
        "from torch import optim\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, datasets, models, optimizers\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from matplotlib import cm\n",
        "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
        "%matplotlib widget\n",
        "\n",
        "import mpl_toolkits\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpG9QCI4TICa"
      },
      "source": [
        "1.0 Mounting the Drive and creating the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nN-W2heZLBnw",
        "outputId": "ee4f457e-7bc2-4ddb-c8bc-60702805032b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2x-OQbMLte12"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# open the file in the write mode\n",
        "f = open('/drive/My Drive/ME 780/TestDataset.csv', 'w')\n",
        "\n",
        "# create the csv writer\n",
        "writer = csv.writer(f)\n",
        "\n",
        "#Grabbing points for x1 and x2\n",
        "x1 = np.linspace(-2, 2, num=16, endpoint=False)\n",
        "x2 = np.linspace(-2, 2, num=16, endpoint=False)\n",
        "\n",
        "\n",
        "\n",
        "#Replacing 0 to avoid dividing by zero\n",
        "x1z = np.where(x1 == 0.)\n",
        "x2z = np.where(x2 == 0.)\n",
        "\n",
        "x1[x1z] = 0.001\n",
        "x2[x2z] = 0.001\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "writer.writerow(['X1', 'X2', 'Y1', 'Y2'])\n",
        "\n",
        "c1 = 0\n",
        "c2 = 0\n",
        "for i in x1:\n",
        "  for j in x2:\n",
        "    rho = i**2 + j**2\n",
        "    y1 = i*np.exp(-rho)\n",
        "    term1 = np.cos(rho)\n",
        "    y2 = np.divide(term1, j)\n",
        "    row = [i, j, y1, y2]\n",
        "    # write a row to the csv file\n",
        "    writer.writerow(row)\n",
        "    c2 +=1\n",
        "  c2 = 0\n",
        "  c1 +=1\n",
        "f.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuMi_eftby-v"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# open the file in the write mode\n",
        "f = open('/drive/My Drive/ME 780/RandomDataset4.csv', 'w')\n",
        "\n",
        "# create the csv writer\n",
        "writer = csv.writer(f)\n",
        "\n",
        "\n",
        "#Grabbing points for x1 and x2\n",
        "x1 = np.linspace(-2,2,num=100, endpoint = False)\n",
        "x2 = np.linspace(-2,2,num=100, endpoint = False)\n",
        "\n",
        "\n",
        "#Replacing 0 to avoid dividing by zero\n",
        "x1z = np.where(x1 == 0.)\n",
        "x2z = np.where(x2 == 0.)\n",
        "\n",
        "x1[x1z] = 0.001\n",
        "x2[x2z] = 0.001\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "writer.writerow(['X1', 'X2', 'Y1', 'Y2'])\n",
        "\n",
        "c1 = 0\n",
        "c2 = 0\n",
        "while c1< 32:\n",
        "  while c2 < 32:\n",
        "    x_1 = random.choice(x1)\n",
        "    x_2 = random.choice(x2)\n",
        "    rho = x_1**2 + x_2**2\n",
        "    y1 = x_1*np.exp(-rho)\n",
        "    term1 = np.cos(rho)\n",
        "    y2 = np.divide(term1, x_2)\n",
        "    row = [x_1, x_2, y1, y2]\n",
        "    # write a row to the csv file\n",
        "    writer.writerow(row)\n",
        "    c2 +=1\n",
        "  c2 = 0\n",
        "  c1 +=1\n",
        "f.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q70LbDVTN-f"
      },
      "source": [
        "2.0 Reading from the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sb_7-D8aw5fr"
      },
      "outputs": [],
      "source": [
        "dfTest = pd.read_csv('/drive/My Drive/ME 780/TestDataset.csv')\n",
        "\n",
        "\n",
        "df = pd.read_csv('/drive/My Drive/ME 780/RandomDataset4.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKyHZQxovHk3"
      },
      "source": [
        "3.0 Attempting to Plot the resulting Data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJmu44NPEt6E"
      },
      "outputs": [],
      "source": [
        "def y1(x1, x2):\n",
        "  return x1*np.exp(-(x1**2 + x2**2))\n",
        "\n",
        "def y2(x1,x2):\n",
        "  rho = x1**2 + x2**2\n",
        "  term1 = np.cos(rho)\n",
        "  return np.cos(rho)/x2\n",
        "\n",
        "x1 = dfTest[\"X1\"]\n",
        "x2 = dfTest[\"X2\"]\n",
        "\n",
        "\n",
        "\n",
        "arrx1 = x1.values\n",
        "arrx2 = x2.values\n",
        "\n",
        "\n",
        "newx1 = arrx1.reshape(16,16)\n",
        "newx2 = arrx2.reshape(16,16)\n",
        "\n",
        "\n",
        "ex1, ex2 = np.meshgrid(newx1, newx2)\n",
        "\n",
        "\n",
        "y1 = y1(ex1,ex2)\n",
        "y2 = y2(ex1,ex2)\n",
        "\n",
        "\n",
        "fig=plt.figure()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.gca(projection='3d')\n",
        "surf1 = ax.plot_surface(ex1, ex2, y1)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.gca(projection='3d')\n",
        "surf2 = ax.plot_surface(ex1, ex2, y2)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lfr65bNCvQKk"
      },
      "source": [
        "4.0 Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsCuoo_e-LXL"
      },
      "outputs": [],
      "source": [
        "#Onto the neural network part of this\n",
        "x1 = df[\"X1\"]\n",
        "x2 = df[\"X2\"]\n",
        "arrx1 = x1.values\n",
        "arrx2 = x2.values\n",
        "\n",
        "\n",
        "# copy the data\n",
        "df_min_max_scaled = df.copy()\n",
        "  \n",
        "# apply normalization techniques by Column 1\n",
        "column1 = \"X1\"\n",
        "df_min_max_scaled[column1] = (df_min_max_scaled[column1] - df_min_max_scaled[column1].min()) / (df_min_max_scaled[column1].max() - df_min_max_scaled[column1].min())  \n",
        "column2 = \"X2\"\n",
        "df_min_max_scaled[column2] = (df_min_max_scaled[column2] - df_min_max_scaled[column2].min()) / (df_min_max_scaled[column2].max() - df_min_max_scaled[column2].min())      \n",
        "column3 = \"Y1\"\n",
        "df_min_max_scaled[column3] = (df_min_max_scaled[column3] - df_min_max_scaled[column3].min()) / (df_min_max_scaled[column3].max() - df_min_max_scaled[column3].min())   \n",
        "column4 = \"Y2\"\n",
        "df_min_max_scaled[column4] = (df_min_max_scaled[column4] - df_min_max_scaled[column4].min()) / (df_min_max_scaled[column4].max() - df_min_max_scaled[column4].min())  \n",
        "  \n",
        "\n",
        "# copy the data\n",
        "df_min_max_scaled_Test = dfTest.copy()\n",
        "  \n",
        "# apply normalization techniques by Column 1\n",
        "column1 = \"X1\"\n",
        "df_min_max_scaled_Test[column1] = (df_min_max_scaled[column1] - df_min_max_scaled[column1].min()) / (df_min_max_scaled[column1].max() - df_min_max_scaled[column1].min())  \n",
        "column2 = \"X2\"\n",
        "df_min_max_scaled_Test[column2] = (df_min_max_scaled[column2] - df_min_max_scaled[column2].min()) / (df_min_max_scaled[column2].max() - df_min_max_scaled[column2].min())      \n",
        "column3 = \"Y1\"\n",
        "df_min_max_scaled_Test[column3] = (df_min_max_scaled[column3] - df_min_max_scaled[column3].min()) / (df_min_max_scaled[column3].max() - df_min_max_scaled[column3].min())   \n",
        "column4 = \"Y2\"\n",
        "df_min_max_scaled_Test[column4] = (df_min_max_scaled[column4] - df_min_max_scaled[column4].min()) / (df_min_max_scaled[column4].max() - df_min_max_scaled[column4].min())  \n",
        "  \n",
        "\n",
        "\n",
        "X_train = df_min_max_scaled[[\"X1\", \"X2\"]]\n",
        "Y_train = df_min_max_scaled[[\"Y1\", \"Y2\"]]\n",
        "\n",
        "X_test = df_min_max_scaled_Test[[\"X1\", \"X2\"]]\n",
        "Y_test = df_min_max_scaled_Test[[\"Y1\", \"Y2\"]]\n",
        "\n",
        "\n",
        "\n",
        "#Defining layer components\n",
        "inputs = keras.Input(shape=(2,))\n",
        "\n",
        "dense = layers.Dense(64, activation=\"relu\")\n",
        "x = dense(inputs)\n",
        "\n",
        "#Splitting the final layer into two for activation function adjustment\n",
        "y1_pred = layers.Dense(1, name=\"Y1\", activation=keras.activations.linear, bias_initializer='zeros' )(x)\n",
        "\n",
        "y2_pred = layers.Dense(1, name=\"Y2\", activation=keras.activations.linear, bias_initializer='zeros' )(x)\n",
        "\n",
        "\n",
        "# Creating the model and indicating inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs=inputs,\n",
        "    outputs=[y1_pred,y2_pred],\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "#Setting some hyperparameters\n",
        "tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01,\n",
        "    momentum=0.4,\n",
        "    name='SGD',\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\",\n",
        ")\n",
        "\n",
        "\n",
        "#Setting optimizers and loss functions\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss={\n",
        "        \"Y1\": keras.losses.MeanSquaredError(),\n",
        "        \"Y2\": keras.losses.MeanSquaredError(),\n",
        "    },\n",
        "    loss_weights={\"Y1\": 1.0, \"Y2\": 0.1},\n",
        ")\n",
        "\n",
        "\n",
        "#training the model and exporting insights\n",
        "history = model.fit(X_train, Y_train,\n",
        "    epochs=50,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWmkeIBC1Uqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqbhLbSyvYCH"
      },
      "source": [
        "5.0 Evaluating the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE2TLC7L2f57"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['Y1_loss'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['Y2_loss'])\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(\n",
        "    x=X_test,\n",
        "    y=Y_test,\n",
        "    batch_size=None,\n",
        "    verbose='auto',\n",
        "    sample_weight=None,\n",
        "    steps=None,\n",
        "    callbacks=None,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    use_multiprocessing=False,\n",
        "    return_dict=False,\n",
        ")\n",
        "\n",
        "y1_pred, y2_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvC7s2rG2yFX"
      },
      "source": [
        "6.0 Plotting the Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P5601Bq_pCP"
      },
      "outputs": [],
      "source": [
        "def y1(x1, x2):\n",
        "  return x1*np.exp(-(x1**2 + x2**2))\n",
        "\n",
        "def y2(x1,x2):\n",
        "  rho = x1**2 + x2**2\n",
        "  term1 = np.cos(rho)\n",
        "  return np.cos(rho)/x2\n",
        "\n",
        "# I think i need to unnormalize\n",
        "x1 = X_test[\"X1\"]\n",
        "x2 = X_test[\"X2\"]\n",
        "y1_test = Y_test[\"Y1\"]\n",
        "y2_test = Y_test[\"Y2\"]\n",
        "\n",
        "#y1_pred, y2_pred = model.predict(X_test)\n",
        "\n",
        "arrx1 = x1.values\n",
        "arrx2 = x2.values\n",
        "arry1 = y1_test.values\n",
        "arry2 = y2_test.values\n",
        "reshapeto = len(x1)\n",
        "\n",
        "newx1 = arrx1.reshape(reshapeto, 1)\n",
        "newx2 = arrx2.reshape(reshapeto, 1)\n",
        "\n",
        "\n",
        "nnewx1 = newx1.reshape(16,16)\n",
        "nnewx2 = newx2.reshape(16,16)\n",
        "newy1 = arry1.reshape(16,16)\n",
        "newy2 = arry2.reshape(16,16)\n",
        "\n",
        "newy1_pred = y1_pred.reshape(16,16)\n",
        "newy2_pred = y2_pred.reshape(16,16)\n",
        "\n",
        "ex1, ex2 = np.meshgrid(newx1, newx2)\n",
        "\n",
        "y1 = y1(nnewx1,nnewx2)\n",
        "y2 = y2(nnewx1,nnewx2)\n",
        "\n",
        "why1 = np.empty([256,256])\n",
        "why2 = np.empty([256,256])\n",
        "input = np.empty([1,2])\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "plt.legend(loc='upper left')\n",
        "#surf1 = ax.plot_surface(nnewx1, nnewx2, y1, label=\"Test data\")\n",
        "ax.scatter(newx1, newx2, y1_pred, label='Predicted')\n",
        "ax.scatter(newx1, newx2, newy1, label = \"Test data\")\n",
        "ax.set_xlabel('X1 Label')\n",
        "ax.set_ylabel('X2 Label')\n",
        "ax.set_zlabel('Y1 Label')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "plt.legend(loc='upper left')\n",
        "#surf1 = ax.plot_surface(nnewx1, nnewx2, y1, label=\"Test data\")\n",
        "ax.scatter(newx1, newx2, y2_pred, label='Predicted')\n",
        "ax.scatter(newx1, newx2, newy2, label = \"Test data\")\n",
        "ax.set_xlabel('X1 Label')\n",
        "ax.set_ylabel('X2 Label')\n",
        "ax.set_zlabel('Y2 Label')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}